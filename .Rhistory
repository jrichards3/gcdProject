Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", delimter="|")
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|")
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|")
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|", fill=TRUE)
summary(Bayfront20131213)
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|", fill=TRUE, header=TRUE, row.names=1)
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|", fill=TRUE, header=TRUE)
summary(Bayfront20131213)
view(CaptureID|CreationDate|FileID|FileDescription|AccountNumber|RegistrationDate|AdmitDate|ServiceDate|DischargeDate|ChargeOffDate|LastPaymentDate|FinancialClass|FinancialClassDescription|PatientType|PatientTypeDescription|PresentationPoint|Facility|FacilityDescription|AccountBalance|TotalCharges|TotalPayments|TotalAdjustments|TotalInsurancePayments|TotalPatientPayments|LastPatientPayment|PatientName|PatientSSN|PatientDOB|PatientGender|PatientMaritalStatus|PatientAddress1|PatientAddress2|PatientCity|PatientState|PatientZip|PatientMailReturnFlag|PatientHomePhone|PatientWorkPhone|PatientEmployerName|PatientEmployerAddress1|PatientEmployerAddress2|PatientEmployerCity|PatientEmployerState|PatientEmployerZip|PatientEmployerPhone|GuarantorName|GuarantorRelationshipToPatient|GuarantorSSN|GuarantorDOB|GuarantorGender|GuarantorMaritalStatus|GuarantorAddress1|GuarantorAddress2|GuarantorCity|GuarantorState|GuarantorZip|GuarantorMailReturnFlag|GuarantorHomePhone|GuarantorWorkPhone|GuarantorEmployerName|GuarantorEmployerAddress1|GuarantorEmployerAddress2|GuarantorEmployerCity|GuarantorEmployerState|GuarantorEmployerZip|GuarantorEmployerPhone|PrimaryInsuranceName|PrimaryInsuranceID|PrimaryInsuranceGroup|PrimaryInsuranceIPLAN|PrimaryInsuranceAddress1|PrimaryInsuranceAddress2|PrimaryInsuranceCity|PrimaryInsuranceState|PrimaryInsuranceZip|PrimaryInsurancePhone|SecondaryInsuranceName|SecondaryInsuranceID|SecondaryInsuranceGroup|SecondaryInsuranceIPLAN|SecondaryInsuranceAddress1|SecondaryInsuranceAddress2|SecondaryInsuranceCity|SecondaryInsuranceState|SecondaryInsuranceZip|SecondaryInsurancePhone|TertiaryInsuranceName|TertiaryInsuranceID|TertiaryInsuranceGroup|TertiaryInsuranceIPLAN|TertiaryInsuranceAddress1|TertiaryInsuranceAddress2|TertiaryInsuranceCity|TertiaryInsuranceState|TertiaryInsuranceZip|TertiaryInsurancePhone|AdmittingPhysicianUPIN|AdmittingPhysicianName|AttendingPhysicianUPIN|AttendingPhysicianName|LastAgencyName|LastAgencyPlacedDate|LastAgencyReturnDate|LastAgencyPlacedAmount|LastAgencyRecoveryAmount|LastAgencyAdjustmentAmount|LastAgencyRecallAmount|AttorneyName|AttorneyAddress1|AttorneyAddress2|AttorneyCity|AttorneyState|AttorneyZip|AttorneyPhone|Source|OriginalFinancialClass|OriginalFinancialClassDescription|PriorFinancialClass|PriorFinancialClassDescription|DiagnosisCode1|DiagnosisCode2|DiagnosisCode3|PortfolioID|PortfolioName|PurchaseDate|OriginalCreditorID|OriginalCreditorName|DebtbuyingSystemAccountNumber|DebtbuyingSystemStatus|DebtbuyingSystemActiveOrClosed|DebtbuyingSystemPurchaseBalance|DollarRating|DollarScore|CollectionRating|CollectionScore|SpecialScore|LiquidationRating|LiquidationScore|Custom1|AgingDateDescription|AgingDate|AgingYear|SelfPayIndicator|InsuranceGroup|AgeBucket|PrimaryState|SelfPayBreakout|MiscInfo|MRN|FacilityTaxID|Division|DivisionDesc|PatientIdentifier|TransportDate|AmbServiceName|AmbServiceDesc|AmbPickUpLoc|AmbDropOffLoc|Comment1|Comment2|EXTRA
)
view(Bayfront20131213)
View(Bayfront20131213)
summary(Bayfront20131213)
Bayfront20131213 <- read.table("Z:/DBPROD/Pur/Bayfront/BF1/Bayfront-id363_20140225.txt", sep="|", fill=TRUE,quote="", header=TRUE)
summary(Bayfront20131213)
nrow
install.packages("swirl")
library('swirl')
swirl()
5 + 7
x <- 5+7
x
y <- x-3
y
c(1.1,9,3.14)
z <- c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div < z/my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
z*2+1000
my
my_div
1:20
pi:10
15:1
?`:`
seq(1,20)
seq(0,10,by=0.5)
seq(5,10,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along = my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2), times=10)
rep(c(0,1,2), each=10)
c(.5,55,-10,6)
c(0.5,55,-10,6)
num_vect <- c(0.5,55,-10,6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My","name","is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char,"James Richards")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep=" ")
past(1:3,c("x","y","z"),sep="")
paste(1:3,c("x","y","z"),sep="")
paste(1:3, c("x", "y", "z"), sep = "")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS,1:4,sep="-")
x <- c(44,NA,5,NA)
X*3
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y,z),100)
is.na(my_data)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x >0]
x[!is.na(x) & x>0]
c(x[3],x[5],x[7])
idx < - c(3,5,7)
idx <- c(3,5,7)
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo=11, bar=2, norf=NA)
vect
names
names(vect)
vect2 <- c(11,2,NA)
names(vect2) <- c("foo","bar","norf")
names(vect2)
identical(vect,vect2)
vect["bar"]
vect["foo","bar"]
vect[c("foo","bar")]
my_vector <- c(1:20)
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_Vector) <- c(4,5)
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(1:20,4,5)
identical(my_matrix,my_matrix2)
patients <- c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients,my_matrix)
my_data
class(my_data)
cnames <- c("patient","age","weight","bp","rating","test")
colnames
colnames(my_data) <- cnames
my_data
mymat <- matrix(c(1,0,5,2,1,6,3,4,0, nrow=3, ncol=3)
mymat <- matrix(c(1,1,2,2,3,3,4,4,5), nrow=3, ncol=3)
mymat <- matrix(c(1,1,2,2,3,3,4,4,5), nrow=3, ncol=3)
mymat
solve(mymat)
m*m
mymat * mymat
mymat %*% mymat
fsd
data <- read.csv("U:/Class/R Programming/Quiz/hw1_data.csv")
View(data)
ozone <- data[data.Ozone]
ozone <- data.Ozone
data.Ozone
data[data$Ozone]
data$Ozone
data$Ozone(is.na)
data$Ozone(is.na())
data$Ozone(is.na(data$Ozone))
ozone <- complete.cases(data$Ozone)
ozone
data$Ozone[ozone]
data$Ozone[!ozone]
bad < data$Ozone[!ozone]
bad < data$Ozone[!ozone]
bad <- data$Ozone[!ozone]
good <- data$Ozone[!ozone]
mean(good)
good <- data$Ozone[ozone]
mean(good)
data[data$Ozone > 31]
data[Ozone > 31]
data[data$Ozone > 31]
\
subset(data, Ozone
>31)
subset(data, Ozone > 31, Temp > 90)
subset(data, Ozone > 31 | Temp > 90)
subdata <- \subset(data, Ozone > 31 | Temp > 90)
subdata <- subset(data, Ozone > 31 | Temp > 90)
mean(subdata)
mean(subdata$Solar.R)
mean(subdata, na.rm=TRUE)
mean(subdata, na.rm=FALSE)
mean(subdata$Solar.R, na.rm=TRUE)
sub_month <- subset(data,Month = 6 )
sub_month
sub_month <- subset(data,Month = 6)
View(subdata)
View(subdata)
View(sub_month)
sub_month <- subset(data,Month == 6)
mean(sub_month$Temp)
sub_month <- subset(data,Month == 5)
max(sub_month$Ozone)
max(sub_month$Ozone,na.rm=TRUE)
subdata <- subset(data, Ozone > 31 | Temp > 90)
Summart(subfata)
Summart(subdata
)
Summart(subdata)
Summary(subdata)
Summary(subdara)
Summary(subdata)
summary()
summary(subdata)
summary(subdata, na.rm=TRUE)
clear()
clear
dataset <- read.csv("U:/Class/Getting and Cleaning Data/quiz/getdata-data-ss06hid (1).csv", header=FALSE)
View(dataset)
quiz <- subset(dataset,VAL = 24)
quiz <- subset(dataset,VAL == 24)
dataset <- read.csv("U:/Class/Getting and Cleaning Data/quiz/getdata-data-ss06hid (1).csv")
View(dataset)
quiz <- subset(dataset,VAL == 24)
quiz
viewdata(quiz)
view(quiz)
View(quiz)
library(gdata)
library(xlsx)
library(xlsx)
install.packages("xlsx")
library(xlsx)
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx")
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",sheetIndex=1,header=TRUE)
View(dat)
sum(dat$Zip*$Ext,na.rm=T)
?read.xlsx
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",sheetIndex=1,header=TRUE,rowIndex=7:15,colIndex=18:23)
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",sheetIndex=1,rowIndex=7:15,colIndex=18:23)
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",rowIndex=7:15,colIndex=18:23)
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",rowIndex=7:15,colIndex=18:23,sheetIndex =1)
colIndex = 7:15
rowIndex = 18:23
dat <- read.xlsx("U:\\Class\\Getting and Cleaning Data\\quiz\\getdata-data-DATA.gov_NGAP.xlsx",rowIndex=rowIndex,colIndex=colIndex,sheetIndex =1)
View(dat)
sum(dat$Zip*$Ext,na.rm=T)
sum(dat$Zip*dat$Ext,na.rm=T)
`getdata.data.ss06pid.(1)` <- read.csv("U:/Class/Getting and Cleaning Data/quiz/getdata-data-ss06pid (1).csv")
View(`getdata.data.ss06pid.(1)`)
library('fread')
library("fread")
fread
fread()
install.packages("fread")
DT <- read.csv("U:/Class/Getting and Cleaning Data/quiz/getdata-data-ss06pid (1).csv")
View(DT)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
library(XML)
install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata data restaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata_data_restaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
fileUrl <- "U:\\Class\\Getting and Cleaning Data\\quiz\\getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
#  Data to be processed should be in  \UCI HAR Dataset from run_analysis.R
mergeData <- function(directory) {
}
mergeData <- function(directory) {
# read the X datasets
path <- paste("./", directory, "/test/X_test.txt", sep="")
test_data <- read.table(path)
path <- paste("./", directory, "/train/X_train.txt", sep="")
train_data <- read.table(path)
# read the activity labels
path <- paste("./", directory, "/activity_labels.txt", sep="")
activity_labels <- read.table(path)
# read the subject labels
path <- paste("./", directory, "/train/subject_train.txt", sep="")
subject_train <- read.table(path)
path <- paste("./", directory, "/test/subject_test.txt", sep="")
subject_test <- read.table(path)
# read the y labels
path <- paste("./", directory, "/train/y_train.txt", sep="")
y_train <- read.table(path)
path <- paste("./", directory, "/test/y_test.txt", sep="")
y_test <- read.table(path)
# merge y activity labels
y_train_labels <- merge(y_train,activity_labels,by="V1")
y_test_labels <- merge(y_test,activity_labels,by="V1")
# merge the data and the respective labels together
train_data <- cbind(subject_train,y_train_labels,train_data)
test_data <- cbind(subject_test,y_test_labels,test_data)
# now then we'll merge the test and training data together
all_data <- rbind(train_data,test_data)
return (all_data)
}
extract_mean_std <- function(data_set, directory) {
path <- paste("./", directory, "/features.txt", sep="")
features_data <- read.table(path)
mean_std_rows <- subset(features_data,  grepl("(mean\\(\\)|std\\(\\))", features_data$V2) )
# set the column headers
colnames(data_set) <- c("Subject","Activity_Id","Activity",as.vector(features_data[,2]))
# extract the data from the merged data where the column names are mean OR std
mean_columns <- grep("mean()", colnames(data_set), fixed=TRUE)
std_columns <- grep("std()", colnames(data_set), fixed=TRUE)
# put both mean and std columns into single vector
mean_std_column_vector <- c(mean_columns, std_columns)
# sort the vector
mean_std_column_vector <- sort(mean_std_column_vector)
# extract the columns with std and mean in their column headers
extracted_data_set <- data_set[,c(1,2,3,mean_std_column_vector)]
return (extracted_data_set)
}
melt_data_and_write_tidy_set <- function(data_set, path_to_tidyset_file) {
# let's melt the data
require(reshape2)
melted_data <- melt(data_set, id=c("Subject","Activity_Id","Activity"))
# cast the data back to the tidy_data format
tidy_data <- dcast(melted_data, formula = Subject + Activity_Id + Activity ~ variable, mean)
# format the column names
col_names_vector <- colnames(tidy_data)
col_names_vector <- gsub("-mean()","Mean",col_names_vector,fixed=TRUE)
col_names_vector <- gsub("-std()","Std",col_names_vector,fixed=TRUE)
col_names_vector <- gsub("BodyBody","Body",col_names_vector,fixed=TRUE)
# put back in the tidy column names
colnames(tidy_data) <- col_names_vector
# write the output into a file
write.table(tidy_data, file=path_to_tidyset_file, sep="\t", row.names=FALSE)
}
merged_data <- merge_data("UCI HAR Dataset")
merged_data <- mergeData("UCI HAR Dataset")
getwd()
setwd("U:\\Class\\Getting and Cleaning Data\\project\\gcdProject")
merged_data <- mergeData("UCI HAR Dataset")
write.table(tidy_data, file=path_to_tidyset_file, sep="\t", row.names=FALSE)
extracted_mean_std_data_set <- extract_mean_std(merged_data, "UCI HAR Dataset")
melt_data_and_write_tidy_set(extracted_mean_std_data_set, "./tidyset.txt")
library(reshape2)
install.packages(reshape2)
install.packages("reshape2")
melt_data_and_write_tidy_set(extracted_mean_std_data_set, "./tidyset.txt")
lib
read_tidy_set <- function(path_to_tidyset_file) {
tidy_set <- read.table(path_to_tidyset_file)
return (tidy_set)
}
tidy_set <- read_tidy_set("./tidyset.txt")
View(tidy_set)
mergeData <- function(directory) {
# read the X datasets
path <- paste("./", directory, "/test/X_test.txt", sep="")
testDataX <- read.table(path)
path <- paste("./", directory, "/train/X_train.txt", sep="")
trainDataX <- read.table(path)
# read the activity labels
path <- paste("./", directory, "/activityLabels.txt", sep="")
activityLabels <- read.table(path)
# read the subject labels
path <- paste("./", directory, "/train/subjectTrain.txt", sep="")
subjectTrain <- read.table(path)
path <- paste("./", directory, "/test/subjectTest.txt", sep="")
subjectTest <- read.table(path)
# read the y labels
path <- paste("./", directory, "/train/trainDataY.txt", sep="")
trainDataY <- read.table(path)
path <- paste("./", directory, "/test/testDataY.txt", sep="")
testDataY <- read.table(path)
# merge y activity labels
trainDataYLabels <- merge(trainDataY,activityLabels,by="V1")
testDataYLabels <- merge(testDataY,activityLabels,by="V1")
# merge the data and the respective labels together
trainDataX <- cbind(subjectTrain,trainDataYLabels,trainDataX)
testDataX <- cbind(subjectTest,testDataYLabels,testDataX)
# now then we'll merge the test and training data together
masterData <- rbind(trainDataX,testDataX)
return (masterData)
}
extractMeanAndStd <- function(dataSet, directory) {
path <- paste("./", directory, "/features.txt", sep="")
featuresData <- read.table(path)
meanAndStdRows <- subset(featuresData,  grepl("(mean\\(\\)|std\\(\\))", featuresData$V2) )
# set the column headers
colnames(dataSet) <- c("Subject","Activity_Id","Activity",as.vector(featuresData[,2]))
# extract the data from the merged data where the column names are mean OR std
meanColumns <- grep("mean()", colnames(dataSet), fixed=TRUE)
stdColumns <- grep("std()", colnames(dataSet), fixed=TRUE)
# put both mean and std columns into single vector
meanStdColumnVector <- c(meanColumns, stdColumns)
# sort the vector
meanStdColumnVector <- sort(meanStdColumnVector)
# extract the columns with std and mean in their column headers
extractedDataSet <- dataSet[,c(1,2,3,meanStdColumnVector)]
return (extractedDataSet)
}
meltDataAndWriteTidySet <- function(dataSet, path_to_tidyset_file) {
}
meltDataAndWriteTidySet <- function(dataSet, path_to_tidyset_file) {
# let's melt the data
require(reshape2)
meltedData <- melt(dataSet, id=c("Subject","Activity_Id","Activity"))
# cast the data back to the tidyData format
tidyData <- dcast(meltedData, formula = Subject + Activity_Id + Activity ~ variable, mean)
# format the column names
colNamesVector <- colnames(tidyData)
colNamesVector <- gsub("-mean()","Mean",colNamesVector,fixed=TRUE)
colNamesVector <- gsub("-std()","Std",colNamesVector,fixed=TRUE)
colNamesVector <- gsub("BodyBody","Body",colNamesVector,fixed=TRUE)
# put back in the tidy column names
colnames(tidyData) <- colNamesVector
# write the output into a file
write.table(tidyData, file=path_to_tidyset_file, sep="\t", row.names=FALSE)
}
merged_data <- mergeData("UCI HAR Dataset")
getwd()
mergeData <- function(directory) {
# read the X datasets
path <- paste("./", directory, "/test/X_test.txt", sep="")
testDataX <- read.table(path)
path <- paste("./", directory, "/train/X_train.txt", sep="")
trainDataX <- read.table(path)
# read the activity labels
path <- paste("./", directory, "/activityLabels.txt", sep="")
activityLabels <- read.table(path)
# read the subject labels
path <- paste("./", directory, "/train/subjectTrain.txt", sep="")
subjectTrain <- read.table(path)
path <- paste("./", directory, "/test/subjectTest.txt", sep="")
subjectTest <- read.table(path)
# read the y labels
path <- paste("./", directory, "/train/trainDataY.txt", sep="")
trainDataY <- read.table(path)
path <- paste("./", directory, "/test/testDataY.txt", sep="")
testDataY <- read.table(path)
# merge y activity labels
trainDataYLabels <- merge(trainDataY,activityLabels,by="V1")
testDataYLabels <- merge(testDataY,activityLabels,by="V1")
# merge the data and the respective labels together
trainDataX <- cbind(subjectTrain,trainDataYLabels,trainDataX)
testDataX <- cbind(subjectTest,testDataYLabels,testDataX)
# now then we'll merge the test and training data together
masterData <- rbind(trainDataX,testDataX)
return (masterData)
}
extractMeanAndStd <- function(dataSet, directory) {
path <- paste("./", directory, "/features.txt", sep="")
featuresData <- read.table(path)
meanAndStdRows <- subset(featuresData,  grepl("(mean\\(\\)|std\\(\\))", featuresData$V2) )
# set the column headers
colnames(dataSet) <- c("Subject","Activity_Id","Activity",as.vector(featuresData[,2]))
# extract the data from the merged data where the column names are mean OR std
meanColumns <- grep("mean()", colnames(dataSet), fixed=TRUE)
stdColumns <- grep("std()", colnames(dataSet), fixed=TRUE)
# put both mean and std columns into single vector
meanStdColumnVector <- c(meanColumns, stdColumns)
# sort the vector
meanStdColumnVector <- sort(meanStdColumnVector)
# extract the columns with std and mean in their column headers
extractedDataSet <- dataSet[,c(1,2,3,meanStdColumnVector)]
return (extractedDataSet)
}
meltDataAndWriteTidySet <- function(dataSet, path_to_tidyset_file) {
# let's melt the data
require(reshape2)
meltedData <- melt(dataSet, id=c("Subject","Activity_Id","Activity"))
# cast the data back to the tidyData format
tidyData <- dcast(meltedData, formula = Subject + Activity_Id + Activity ~ variable, mean)
# format the column names
colNamesVector <- colnames(tidyData)
colNamesVector <- gsub("-mean()","Mean",colNamesVector,fixed=TRUE)
colNamesVector <- gsub("-std()","Std",colNamesVector,fixed=TRUE)
colNamesVector <- gsub("BodyBody","Body",colNamesVector,fixed=TRUE)
# put back in the tidy column names
colnames(tidyData) <- colNamesVector
# write the output into a file
write.table(tidyData, file=path_to_tidyset_file, sep="\t", row.names=FALSE)
}
mergedData <- mergeData("UCI HAR Dataset")
mergeData <- function(directory) {
# read the X datasets
path <- paste("./", directory, "/test/X_test.txt", sep="")
testDataX <- read.table(path)
path <- paste("./", directory, "/train/X_train.txt", sep="")
trainDataX <- read.table(path)
# read the activity labels
path <- paste("./", directory, "/activity_labels.txt", sep="")
activityLabels <- read.table(path)
# read the subject labels
path <- paste("./", directory, "/train/subject_train.txt", sep="")
subjectTrain <- read.table(path)
path <- paste("./", directory, "/test/subject_test.txt", sep="")
subjectTest <- read.table(path)
# read the y labels
path <- paste("./", directory, "/train/y_train.txt", sep="")
trainDataY <- read.table(path)
path <- paste("./", directory, "/test/y_test.txt", sep="")
testDataY <- read.table(path)
# merge y activity labels
trainDataYLabels <- merge(trainDataY,activityLabels,by="V1")
testDataYLabels <- merge(testDataY,activityLabels,by="V1")
# merge the data and the respective labels together
trainDataX <- cbind(subjectTrain,trainDataYLabels,trainDataX)
testDataX <- cbind(subjectTest,testDataYLabels,testDataX)
# now then we'll merge the test and training data together
masterData <- rbind(trainDataX,testDataX)
return (masterData)
}
mergedData <- mergeData("UCI HAR Dataset")
extractedMeanStdDataSet <- extractMeanAndStd(mergedData, "UCI HAR Dataset")
meltDataAndWriteTidySet(extractedMeanStdDataSet, "./tidyset.txt")
